# -*- coding: utf-8 -*-
"""Dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1McASLulvTC7qRUQLgssQMqRsdKdtH-Dc
"""



"""**Datasets**

Dataset is essentially the backbone for all operations, techniques or models used by developers to interpret them. Datasets involve a large amount of data points grouped into one table. Datasets are used in almost all industries today for various reasons.

A dataset is a collection of data that contains data specific to its category and nothing else. This is used to develop Machine Learning models perform Data Analysis, Data and Feature Engineering. Datasets may be structured (Height, weight analysis) or unstructured (audio files, videos, images).

**Types of Datasets**

There are various types of datasets available out there. They are:

**Numerical Dataset**

They include numerical data points that can be solved with equations. These include temperature, humidity, marks and so on.

**Categorical Dataset**
These include categories such as colour, gender, occupation, games, sports and so on.

**Web Dataset**:

These include datasets created by calling APIs using HTTP requests and populating them with values for data analysis. These are mostly stored in JSON (JavaScript Object Notation) formats.

**Time series Dataset**:
These include datasets between a period, for example, changes in geographical terrain over time.

Weather data.
Rainfall measurements.
Temperature readings.
Heart rate monitoring (EKG)
Brain monitoring (EEG)
Quarterly sales.
Stock prices.
Automated stock trading.

**Image Dataset**:

It includes a dataset consisting of images. This is mostly used to differentiate the types of diseases, heart conditions and so on.

scanned documents,
remotely sensed data (for example, satellite images),
and aerial photographs

**Ordered Dataset**:
These datasets contain data that are ordered in ranks, for example, customer reviews, movie ratings and so on.

bills, papers, letters, to-do lists,

**Partitioned Dataset**:
These datasets have data points segregated into different members or different partitions.

data may be partitioned based on date ranges or price ranges

**File-Based Datasets**:
These datasets are stored in files, in Excel as .csv, or .xlsx files.

**Bivariate Dataset**:
In this dataset, 2 classes or features are directly correlated to each other. For example, height and weight in a dataset are directly related to each other.

eg: data of outside temperature versus ice cream sales

**Multivariate Dataset**:
In these types of datasets, as the name suggests 2 or more classes are directly correlated to each other. For example, attendance, and assignment grades are directly correlated to a student’s overall grade.

If we have to measure the length, width, height, volume of a rectangular box, we have to use multiple variables to distinguish between those entities.

**Features of a Dataset**

The features of a dataset may allude to the columns available in the dataset. The features of a dataset are the most critical aspect of the dataset, as based on the features of each available data point, will there be any possibility of deploying models to find the output to predict the features of any new data point that may be added to the dataset.

It is only possible to determine the standard features from some datasets since their functionalities and data would be completely different when compared to other datasets. Some possible features of a dataset are:

**Numerical Features**:
These may include numerical values such as height, weight, and so on. These may be continuous over an interval, or discrete variables.

**Categorical Features**: These include multiple classes/ categories, such as gender, colour, and so on.

**Metadata**:
 Includes a general description of a dataset. Generally in very large datasets, having an idea/ description of the dataset when it’s transferred to a new developer will save a lot of time and improve efficiency.

**Size of the Data**:
 It refers to the number of entries and features it contains in the file containing the Dataset.

**Formatting of Data**:
The datasets available online are available in several formats. Some of them are JSON (JavaScript Object Notation), CSV (Comma Separated Value), XML (eXtensible Markup Language), DataFrame, and Excel Files (xlsx or xlsm). For particularly large datasets, especially involving images for disease detection, while downloading the files from the internet, it comes in zip files which will be needed to extract in the system to individual components.

**Target Variable**:
 It is the feature whose values/attributes are referred to to get outputs from the other features with machine learning techniques.

**Data Entries**:
 These refer to the individual values of data present in the Dataset. They play a huge role in data analysis.

### Methods Used in Datasets
Many methods are applied when it involves working with Datasets. It depends on the reason you work with your given dataset. Some of the common methods that are applied to datasets are:

**1. Loading and Reading Datasets:**
Set of methods that are used in loading and reading the datasets initially to execute the required tasks.

`Eg – read_csv(), read_json(), read_excel() etc.`

**2. Exploratory Data Analysis:**
To perform Data Analysis and visualize it, we use these functions on a dataset to work.

`Eg – head(), tail(), groupby() etc`

**3. Data Preprocessing:**
Before analyzing a dataset, it is preprocessed to remove erroneous values, and mislabeled data points by using specific methods.

`Eg – drop(), fillna(), dropna(), copy() etc`

**4. Data Manipulation:**
Data points in the dataset are arranged/ rearranged to manipulate the features. At some points, even features of the dataset are manipulated to decrease computational complexity and so on. This may involve methods or functions merging columns, adding new data points, and so on.

`Eg – merge(), concat(), join() etc`

**5. Data Visualization:**
Methods used to explain the dataset to people not in the technical field like – the use of bar graphs and charts to provide a pictorial representation of the dataset of the company/ business.

`Eg – plot()`

**6. Data Indexing, Data Subsets:**
Methods that are used to refer to a particular feature in a dataset, we use data indexing or create definitive subsets.

`Eg – iloc()`

**7. Export Data:**
Methods that are used in exporting the data you’ve worked on in different formats as required.

`Eg – to_csv(), to_json() etc`

### Data splits
Go to the below link:
[Dataset splits - Training, Validation, and Test sets](https://mlu-explain.github.io/train-test-validation/#:~:text=It%20is%20best%20practice%20in,final%20evaluation%20of%20the%20model.)

### What is Underfitting and Overfitting; Bias-Variance Tradeoffs

[Underfitting and Overfitting](https://medium.com/geekculture/overfitting-underfitting-and-bias-variance-tradeoff-9e83f4a147c)
"""