{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":29985,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.datasets import load_boston\nfrom sklearn.metrics import mean_squared_error","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using the boston housing data that is prebuilt into `sklearn` ","metadata":{}},{"cell_type":"code","source":"# Load and convert data to DataFrame\ndata = load_boston()\n\ndf = pd.DataFrame(data['data'],columns=data['feature_names'])\ndf.insert(13,'target',data['target'])\ndf.head(5)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center'> Gradient Descent Explained </h1>\n\nBefore we dive in to Stochastic Gradient Descent, You need to understand what gradient descent itself is. \n\nEssentially, gradient descent is an iterative optimization algorithm that aims to get the minimum of a function.\n\nIn other words, if you had a cost function(MSE,MAE,RMSE) and it is quite high, then the objective of gradient descent is to either reduce it greatly to a small value(local minimum), or reduce in completely(global minimum). \n\nIt works by iteratively looping through the dataset and substracting the partial derivative from the current coefficent value times the alpha(learning rate).\nYou can think of gradient descent like this: if I was on top of a mountain, what is the best direction to take a step in? \n\n\n<h2>Learning Rate</h2>\n\nThe learning rate controls the size of each 'step' taken by gradient descent.\n\nIf the learning rate is too large, the gradient descent might miss the global minimum. If the learning rate is too small, then gradient descent wil take to long to converge(reach a point where it is no longer descreasing). \n\n![](https://cdn-images-1.medium.com/max/1000/1*An4tZEyQAYgPAZl396JzWg.png)\n\n<h2>Types of Gradient Descent</h2>\n\n\nThere are three main types of Gradient Descent:\n\n1. Batch Gradient Descent\n2. Stochastic Gradient Descent\n3. Mini-batch gradient Descent\n\n**Batch Gradient Descent**\n\nHere, the **whole** training set(batch) is taken into consideration when caclulating the derivatives. While this may have the smoothest path, it can become extremely slow and computationally expensive to do so. Therefore, it is not ideal for large datasets.\n\n**Stochastic Gradient Descent**\n\nHere, instead of calculating the partial derivative for the whole training set, the calcuation is only done on one **random** sample(stochastic meaning random). This is great because the calcuations are only needed to be done on one training example instead of the whole training set, making it much faster and ideal for large datasets.\n\nHowever,due to its inherent randomness, stochastic gradient descent does not have a smooth descend as in batch gradient descent. This means that it will bounce around, and while it may produce good parameters,they will rarely be optimal.\n\n**Mini-batch Gradient Descent**\n\nInstead of computing the gradients based on the whole training set,or just one training set, it computes it on small random subsets of the training set called **mini batches**.\n\nIt tends to have a much smoother descent than stochastic gradient descent, and is again computationally fast. However, like stochastic gradient descent, it may be stuck on local minima, meaning that the parameters will be good, but not optimal\n\n\nAs suggested by the title, we will be implementing stochastic gradient descent, with a twist!\n\nAn important thing to note is that the initial parameters are randomly initialized. This is known as (you guessed it), Random Initialization!","metadata":{}},{"cell_type":"code","source":"X,y = df.drop('target',axis=1),df['target']\n\nthetas = np.zeros(X.shape[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center'>Cost Functions</h1>","metadata":{}},{"cell_type":"markdown","source":"a cost function,or a loss function, is simply a function that calculates the loss of a hypothesis. These are usually names Evaluation Metrics on Kaggle. Commons ones include:\n\nMSE(Mean Squared Error)\nRMSE(Root Mean Squared Error)\nMAE(Mean Absolute Error)\n\nDifferent cost functions have different pros and cons, but here I will be implementing Mean Squared Error.\n\n![](https://miro.medium.com/max/808/1*-e1QGatrODWpJkEwqP4Jyg.png)","metadata":{}},{"cell_type":"code","source":"def cost_function(X,Y,B):\n    predictions = np.dot(X,B.T)\n    \n    cost = (1/len(Y)) * np.sum((predictions - Y) ** 2)\n    return cost","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ok, so let's test the cost function by using `sklearn's` mean_sqaured_error function to see if we implemented it correctly!","metadata":{}},{"cell_type":"code","source":"cost_function(X,y,thetas)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_error(np.dot(X,thetas.T),y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks Good!","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center'>Stochastic Gradient Descent Implementation</h1>\n\nOk, now let's get into the fun stuff ;)","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center'>Scaling</h1>\n\nIn order for gradient descent to operate properly, we need to scale our features so that they are on a similar scale. This ensures that all the features are on a similiar scale, and helps gradient descent converge quicker and also reduces computational time. \n\nI will be using Min-Max Scaling to scale my features.\n\n![](https://media.geeksforgeeks.org/wp-content/uploads/min-max-normalisation.jpg)","metadata":{}},{"cell_type":"code","source":"X_norm = (X - X.min()) / (X.max() - X.min())\nX = X_norm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center'>Learning Schedule</h1>","metadata":{}},{"cell_type":"markdown","source":"Because of the inherent randomness of Stochastic Gradient Descent, setting the learning rate can prove to be quite a difficult task as the algorithm can never settle at a minimum.\n\nOne solution is to set the learning rate to be initially large(so it can bypass local optima) and then gradually shrink, giving the algorithm a better chance at reaching global minimum.\n\nThis process is known as a *learning schedule*. We will code a simple learning schedule for our algorithm:","metadata":{}},{"cell_type":"code","source":"t0,t1 = 5,50 # learning schedule hyperparams\ndef learning_schedule(t):\n    return t0/(t+t1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the moment you have been waiting for.. Stochastic Gradient Descent from Scratch!","metadata":{}},{"cell_type":"code","source":"def stochastic_gradient_descent(X,y,theta,n_epochs=50):\n    c_hist = [0] * n_epochs\n    for epoch in range(n_epochs):\n        for i in range(len(y)):\n            rand_index = np.random.randint(len(y))\n            ind_x = X[rand_index:rand_index+1]\n            ind_y = y[rand_index:rand_index+1]\n\n            gradients = 2 * ind_x.T.dot(ind_x.dot(theta) - ind_y)\n            eta = learning_schedule(epoch * len(y) + i)\n            theta = theta - eta * gradients\n            c_hist[epoch] = cost_function(ind_x,ind_y,theta)\n    return theta,c_hist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"th_n,cost_history = stochastic_gradient_descent(X,y,thetas)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ok, now let's evaluate to see how well the algorithm performed","metadata":{}},{"cell_type":"code","source":"mean_squared_error(np.dot(X,th_n.T),y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow! From 592 to 29, definitely an improvement! Let's see a line plot of the cost function by the number of epochs.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(50),cost_history)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks for reading, I hope you enjoyed it and learned something new. Make sure to upvote!","metadata":{}}]}